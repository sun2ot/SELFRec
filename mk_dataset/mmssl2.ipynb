{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理 tiny 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ifashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('ifashion_tiny/mmssl', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "user2id: dict[str, int] = {}\n",
    "item2id: dict[str, int] = {}\n",
    "\n",
    "with open(\"ifashion_tiny/ui_dict.json\", 'r') as file:\n",
    "    ui_dict: dict[str, dict[str, int]] = json.load(file)\n",
    "\n",
    "item_set = set()\n",
    "for user, item_ratings in ui_dict.items():\n",
    "    user2id[user] = len(user2id)\n",
    "    item_set.update(item_ratings.keys())\n",
    "\n",
    "for idx, item in enumerate(item_set):\n",
    "    item2id[item] = idx\n",
    "\n",
    "os.makedirs(\"ifashion_tiny/remap\", exist_ok=True)\n",
    "with open(\"ifashion_tiny/remap/user2id.json\", 'w', encoding='utf-8') as f1:\n",
    "    json.dump(user2id, f1, ensure_ascii=False)\n",
    "with open(\"ifashion_tiny/remap/item2id.json\", 'w', encoding='utf-8') as f2:\n",
    "    json.dump(item2id, f2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38403\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "with open(\"ifashion_tiny/remap/user2id.json\", 'r', encoding='utf-8') as f1:\n",
    "    uid = json.load(f1)\n",
    "print(len(uid))\n",
    "\n",
    "with open(\"ifashion_tiny/remap/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    iid = json.load(f2)\n",
    "print(len(iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交互数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(\"ifashion_tiny/remap/user2id.json\", 'r', encoding='utf-8') as f1:\n",
    "    user2id: dict[str, int] = json.load(f1)\n",
    "\n",
    "with open(\"ifashion_tiny/remap/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id: dict[str, int] = json.load(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别将各个数据集进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_save(interactions: dict[str, set]) -> dict[str, list[int]]:\n",
    "    \"\"\"将dict.values转为list\"\"\"\n",
    "    it_dict = {}\n",
    "    for k,v in interactions.items():\n",
    "        it_dict[k] = list(v)\n",
    "    return it_dict\n",
    "\n",
    "def ds_convert_json(txt_path: str, json_path: str, user2id: dict[str, int], item2id: dict[str, int]):\n",
    "    out_json: dict[str, set] = defaultdict(set[int])\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            user, item, _ratings = line.split(' ')\n",
    "            out_json[str(user2id[user])].add(item2id[item])\n",
    "    \n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(pre_save(out_json), f, ensure_ascii=False)\n",
    "    print(f\"{txt_path} convert to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifashion_tiny/train.txt convert to ifashion_tiny/mmssl/train.json\n"
     ]
    }
   ],
   "source": [
    "ds_convert_json(\n",
    "    'ifashion_tiny/train.txt',\n",
    "    'ifashion_tiny/mmssl/train.json',\n",
    "    user2id, item2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifashion_tiny/val.txt convert to ifashion_tiny/mmssl/val.json\n"
     ]
    }
   ],
   "source": [
    "ds_convert_json(\n",
    "    'ifashion_tiny/val.txt',\n",
    "    'ifashion_tiny/mmssl/val.json',\n",
    "    user2id, item2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifashion_tiny/test.txt convert to ifashion_tiny/mmssl/test.json\n"
     ]
    }
   ],
   "source": [
    "ds_convert_json(\n",
    "    'ifashion_tiny/test.txt',\n",
    "    'ifashion_tiny/mmssl/test.json',\n",
    "    user2id, item2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照编码映射转换全局交互数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ifashion_tiny/ui_dict.json\", 'r') as file:\n",
    "    ui_dict: dict[str, dict[str, int]] = json.load(file)\n",
    "\n",
    "remap_ui_dict: dict[str, list[int]] = {}\n",
    "for user, item_ratings in ui_dict.items():\n",
    "    remap_ui_dict[str(user2id[user])] = [item2id[item] for item in item_ratings.keys()]\n",
    "\n",
    "with open(\"ifashion_tiny/remap/remap_ui_list.json\", 'w') as file:\n",
    "    json.dump(remap_ui_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38403\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "with open(\"ifashion_tiny/remap/remap_ui_list.json\", 'r') as file:\n",
    "    d = json.load(file)\n",
    "print(len(d))\n",
    "n=0\n",
    "for u, il in d.items():\n",
    "    if len(il) == 0: n+=1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造 ifashion 稀疏矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def read_user_items(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        user_items = json.load(file)\n",
    "    return user_items\n",
    "\n",
    "with open(\"ifashion_tiny/remap/user2id.json\", 'r', encoding='utf-8') as f1:\n",
    "    user2id: dict[str, int] = json.load(f1)\n",
    "\n",
    "with open(\"ifashion_tiny/remap/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id: dict[str, int] = json.load(f2)\n",
    "\n",
    "def create_sparse_matrix(user_items: dict[str, list[int]], user2id, item2id):\n",
    "    # 获取用户和项目的最大编号\n",
    "    max_user = max(list(user2id.values()))\n",
    "    max_item = max(list(item2id.values()))\n",
    "\n",
    "    # 初始化稀疏矩阵\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    for user, items in user_items.items():\n",
    "        user_id = int(user)\n",
    "        for item_id in items:\n",
    "            rows.append(user_id)\n",
    "            cols.append(item_id)\n",
    "            data.append(1.0)  # ratings设为1.0\n",
    "\n",
    "    # 构造稀疏矩阵\n",
    "    train_mat = csr_matrix((data, (rows, cols)), shape=(max_user + 1, max_item + 1))\n",
    "    return train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "user_items = read_user_items('ifashion_tiny/remap/remap_ui_list.json')\n",
    "\n",
    "# 构造稀疏矩阵\n",
    "train_mat = create_sparse_matrix(user_items, user2id, item2id)\n",
    "\n",
    "# 保存稀疏矩阵到文件\n",
    "with open('ifashion_tiny/mmssl/train_mat', 'wb') as file:\n",
    "    pickle.dump(train_mat, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38403, 20000)\n"
     ]
    }
   ],
   "source": [
    "with open('ifashion_tiny/mmssl/train_mat', 'rb') as file:\n",
    "    matrix = pickle.load(file)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多模态数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image embs: 100%|██████████| 20000/20000 [00:00<00:00, 685198.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from safetensors.numpy import load_file\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "with open(\"ifashion_tiny/remap/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id = json.load(f2)\n",
    "\n",
    "image_id2embs: dict[str, np.ndarray] = {}\n",
    "image_ndarrays = load_file(\"ifashion_ds/ifashion_image.safetensors\")\n",
    "\n",
    "for item in tqdm(item2id, desc='image embs'):\n",
    "    image_id2embs[item2id[item]] = np.squeeze(image_ndarrays[item])\n",
    "\n",
    "# 提取键并排序\n",
    "sorted_keys = sorted(image_id2embs.keys(), key=int)\n",
    "sorted_arrays = [image_id2embs[key] for key in sorted_keys]\n",
    "result_array = np.stack(sorted_arrays, axis=0)  # (all_item_num, dim)\n",
    "\n",
    "print(result_array.shape)\n",
    "np.save('ifashion_tiny/mmssl/image_feat.npy', result_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text embs: 100%|██████████| 20000/20000 [00:00<00:00, 886651.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from safetensors.numpy import load_file\n",
    "from safetensors import safe_open\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "with open(\"ifashion_tiny/remap/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id = json.load(f2)\n",
    "\n",
    "text_id2embs: dict[str, np.ndarray] = {}\n",
    "text_ndarrays = load_file(\"ifashion_ds/ifashion_text.safetensors\")\n",
    "\n",
    "for item in tqdm(item2id, desc='text embs'):\n",
    "    text_id2embs[item2id[item]] = np.squeeze(text_ndarrays[item])\n",
    "\n",
    "# 提取键并排序\n",
    "sorted_keys = sorted(text_id2embs.keys(), key=int)\n",
    "sorted_arrays = [text_id2embs[key] for key in sorted_keys]\n",
    "result_array = np.stack(sorted_arrays, axis=0)  # (all_item_num, dim)\n",
    "\n",
    "print(result_array.shape)\n",
    "np.save('ifashion_tiny/mmssl/text_feat.npy', result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "image_feat.npy\n",
      "     40,960,128 100%  394.26MB/s    0:00:00 (xfr#1, to-chk=5/6)\n",
      "test.json\n",
      "      1,116,489 100%   10.44MB/s    0:00:00 (xfr#2, to-chk=4/6)\n",
      "text_feat.npy\n",
      "     81,920,128 100%  260.42MB/s    0:00:00 (xfr#3, to-chk=3/6)\n",
      "train.json\n",
      "      2,032,104 100%    6.35MB/s    0:00:00 (xfr#4, to-chk=2/6)\n",
      "train_mat\n",
      "      4,747,227 100%   14.28MB/s    0:00:00 (xfr#5, to-chk=1/6)\n",
      "val.json\n",
      "        320,381 100%  983.87kB/s    0:00:00 (xfr#6, to-chk=0/6)\n",
      "\n",
      "sent 131,128,984 bytes  received 130 bytes  87,419,409.33 bytes/sec\n",
      "total size is 131,096,457  speedup is 1.00\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rsync -avcP ifashion_tiny/mmssl/* /home/yzh/code/MMSSL/MMSSL/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
