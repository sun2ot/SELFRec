{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理 tiny 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ifashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码映射\n",
    "\n",
    "先用户再项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first uid: 0\n",
      "last uid: 38402\n",
      "first iid: 38403\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "user2id: dict[str, int] = {}\n",
    "item2id: dict[str, int] = {}\n",
    "item_set = set()\n",
    "\n",
    "with open('ifashion_tiny/ui_dict.json', 'r') as file:\n",
    "    ui_dict: dict[str, dict[str, int]] = json.load(file)\n",
    "\n",
    "# 用户编号\n",
    "for user, item_ratings in ui_dict.items():\n",
    "    user2id[user] = len(user2id)\n",
    "    item_set.update(item_ratings.keys())\n",
    "\n",
    "# 获取用户编号的最大值\n",
    "max_user_id = max(user2id.values()) if user2id else -1\n",
    "assert max_user_id != -1\n",
    "\n",
    "# 项目编号(接着用户编号继续)\n",
    "for item in item_set:\n",
    "    item2id[item] = max_user_id + 1\n",
    "    max_user_id += 1\n",
    "\n",
    "print(\"first uid:\", list(user2id.values())[0])\n",
    "print(\"last uid:\", list(user2id.values())[-1])\n",
    "print(\"first iid:\", list(item2id.values())[0])\n",
    "\n",
    "os.makedirs(\"ifashion_tiny/remap_col\", exist_ok=True)\n",
    "with open(\"ifashion_tiny/remap_col/user2id.json\", 'w', encoding='utf-8') as f1:\n",
    "    json.dump(user2id, f1, ensure_ascii=False)\n",
    "with open(\"ifashion_tiny/remap_col/item2id.json\", 'w', encoding='utf-8') as f2:\n",
    "    json.dump(item2id, f2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38403\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "with open(\"ifashion_tiny/remap_col/user2id.json\", 'r', encoding='utf-8') as f1:\n",
    "    uid = json.load(f1)\n",
    "print(len(uid))\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    iid = json.load(f2)\n",
    "print(len(iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多模态特征\n",
    "\n",
    "图像特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image embs: 100%|██████████| 51939/51939 [00:00<00:00, 507248.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 512])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from safetensors.torch import load_file\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id: dict[str, int] = json.load(f2)\n",
    "\n",
    "image_id2embs: dict[int, torch.Tensor] = {}\n",
    "image_tensors = load_file(\"ifashion_ds/ifashion_image.safetensors\")\n",
    "\n",
    "for item in tqdm(image_tensors, desc='image embs'):\n",
    "    if item not in item2id:\n",
    "        continue\n",
    "    image_id2embs[item2id[item]] = torch.squeeze(image_tensors[item], dim=0)\n",
    "\n",
    "# 提取键并排序\n",
    "sorted_keys = sorted(image_id2embs.keys(), key=int)\n",
    "assert sorted_keys[1] > sorted_keys[0]\n",
    "sorted_tensors = [image_id2embs[key] for key in sorted_keys]\n",
    "result_tensor = torch.stack(sorted_tensors, dim=0)  # (all_item_num, dim)\n",
    "\n",
    "print(result_tensor.shape)\n",
    "os.makedirs('ifashion_tiny/mmgcn', exist_ok=True)\n",
    "torch.save(result_tensor, 'ifashion_tiny/mmgcn/v_feat.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text embs: 100%|██████████| 51939/51939 [00:00<00:00, 601323.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 1024])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from safetensors.torch import load_file\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id: dict[str, int] = json.load(f2)\n",
    "\n",
    "text_id2embs: dict[int, torch.Tensor] = {}\n",
    "text_tensors = load_file(\"ifashion_ds/ifashion_text.safetensors\")\n",
    "\n",
    "for item in tqdm(text_tensors, desc='text embs'):\n",
    "    if item not in item2id:\n",
    "        continue\n",
    "    text_id2embs[item2id[item]] = torch.squeeze(text_tensors[item], dim=0)\n",
    "\n",
    "# 提取键并排序\n",
    "sorted_keys = sorted(text_id2embs.keys(), key=int)\n",
    "assert sorted_keys[1] > sorted_keys[0]\n",
    "sorted_tensors = [text_id2embs[key] for key in sorted_keys]\n",
    "result_tensor = torch.stack(sorted_tensors, dim=0)  # (all_item_num, dim)\n",
    "\n",
    "print(result_tensor.shape)\n",
    "os.makedirs('ifashion_tiny/mmgcn', exist_ok=True)\n",
    "torch.save(result_tensor, 'ifashion_tiny/mmgcn/t_feat.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交互数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集其实就是将逐行的 interactions 用 `.npy` 存起来，内容一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251914, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/user2id.json\", 'r', encoding='utf-8') as f1:\n",
    "    user2id: dict[str, int] = json.load(f1)\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id: dict[str, int] = json.load(f2)\n",
    "\n",
    "user_item_pairs = []\n",
    "\n",
    "with open('ifashion_tiny/train.txt', 'r') as train_file:\n",
    "    for line in train_file:\n",
    "        user, item, _ratings = line.split(' ')\n",
    "        user_item_pairs.append([user2id[user], item2id[item]])\n",
    "\n",
    "user_item_array = np.array(user_item_pairs)\n",
    "print(user_item_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ifashion_tiny/mmgcn/train.npy', user_item_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试/验证集由于作者使用了一个很怪的格式，所以只能手动处理了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def v2list(interactions: dict[int, set]) -> dict[int, list[int]]:\n",
    "    ui_dict = {}\n",
    "    for k,v in interactions.items():\n",
    "        ui_dict[k] = list(v)\n",
    "    return ui_dict\n",
    "\n",
    "def trans_ds(txt_path: str, save_path: str, user2id: dict[str, int], item2id: dict[str, int]):\n",
    "    out_json: dict[int, set] = defaultdict(set[int])\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            user, item, _ratings = line.split(' ')\n",
    "            out_json[user2id[user]].add(item2id[item])\n",
    "\n",
    "    ui_dict = v2list(out_json)\n",
    "    array = []\n",
    "    for user, items in ui_dict.items():\n",
    "        merge = [int(user)]\n",
    "        merge.extend(items)\n",
    "        array.append(merge)\n",
    "    \n",
    "    np_array = np.array(array, dtype=object)\n",
    "    np.save(save_path, np_array, allow_pickle=True)\n",
    "\n",
    "    print(f\"{txt_path} convert to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifashion_tiny/val.txt convert to ifashion_tiny/mmgcn/val.npy\n",
      "(17165,)\n"
     ]
    }
   ],
   "source": [
    "trans_ds('ifashion_tiny/val.txt', 'ifashion_tiny/mmgcn/val.npy', user2id, item2id)\n",
    "t = np.load('ifashion_tiny/mmgcn/val.npy', allow_pickle=True)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifashion_tiny/test.txt convert to ifashion_tiny/mmgcn/test.npy\n",
      "(38372,)\n"
     ]
    }
   ],
   "source": [
    "trans_ds('ifashion_tiny/test.txt', 'ifashion_tiny/mmgcn/test.npy', user2id, item2id)\n",
    "t = np.load('ifashion_tiny/mmgcn/test.npy', allow_pickle=True)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_feat.pt\n",
      "     81,921,111 100%  402.55MB/s    0:00:00 (xfr#1, to-chk=5/7)\n",
      "test.npy\n",
      "        749,981 100%    2.58MB/s    0:00:00 (xfr#2, to-chk=4/7)\n",
      "train.npy\n",
      "      4,030,752 100%   13.35MB/s    0:00:00 (xfr#3, to-chk=3/7)\n",
      "v_feat.pt\n",
      "     40,961,111 100%  100.42MB/s    0:00:00 (xfr#4, to-chk=1/7)\n",
      "val.npy\n",
      "        252,322 100%  603.94kB/s    0:00:00 (xfr#5, to-chk=0/7)\n",
      "\n",
      "sent 127,947,006 bytes  received 111 bytes  85,298,078.00 bytes/sec\n",
      "total size is 131,027,702  speedup is 1.02\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rsync -avcP ifashion_tiny/mmgcn/ ../../MMGCN/Data/ifashion/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交互字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/user2id.json\", 'r', encoding='utf-8') as f1:\n",
    "    user2id: dict[str, int] = json.load(f1)\n",
    "\n",
    "with open(\"ifashion_tiny/remap_col/item2id.json\", 'r', encoding='utf-8') as f2:\n",
    "    item2id: dict[str, int] = json.load(f2)\n",
    "\n",
    "with open(\"ifashion_tiny/ui_dict.json\", 'r', encoding='utf-8') as f1:\n",
    "    ui_dict: dict[str, dict[str, int]] = json.load(f1)\n",
    "\n",
    "ui_list_dict: dict[int, list[int]] = {}\n",
    "for user, item_ratings in ui_dict.items():\n",
    "    ui_list_dict[int(user2id[user])] = [item2id[item] for item in item_ratings.keys()]\n",
    "\n",
    "user_item_array = np.array(ui_list_dict, dtype=object)\n",
    "np.save('ifashion_tiny/mmgcn/user_item_dict.npy', user_item_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "t = np.load('ifashion_tiny/mmgcn/user_item_dict.npy', allow_pickle=True)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_item_dict.npy\n",
      "      1,569,817 100%  488.61MB/s    0:00:00 (xfr#1, to-chk=2/7)\n",
      "\n",
      "sent 1,570,535 bytes  received 35 bytes  1,047,046.67 bytes/sec\n",
      "total size is 129,485,094  speedup is 82.44\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rsync -avcP ifashion_tiny/mmgcn/ ../../MMGCN/Data/ifashion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
