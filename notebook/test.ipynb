{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def process_bar(num, total):\n",
    "    \"\"\"\n",
    "    绘制CLI进度条\n",
    "\n",
    "    Args:\n",
    "        num (int): 当前完成的任务数量\n",
    "        total (int): 任务的总数量\n",
    "    \"\"\"\n",
    "    # 计算任务完成的比率\n",
    "    rate = float(num) / total\n",
    "    # 根据比率计算需要显示的进度条长度(最长50个字符)\n",
    "    ratenum = int(50 * rate)\n",
    "    # 构造进度条字符串\n",
    "    # Progress: [+++++++          ]50%\n",
    "    r = '\\rProgress: [{}{}]{}%'.format('+' * ratenum, ' ' * (50 - ratenum), ratenum*2)\n",
    "    # 在命令行中写入进度条，\\r用于回到行首，不换行\n",
    "    sys.stdout.write(r)\n",
    "    # 刷新标准输出，确保进度条及时更新\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%"
     ]
    }
   ],
   "source": [
    "process_bar(100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    process_bar(i, 10000)\n",
    "process_bar(10000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "res['u1'] = {}\n",
    "res['u2'] = {}\n",
    "res['u1']['i1'] = 1\n",
    "res['u1']['i2'] = 2\n",
    "res['u2']['i1'] = 3\n",
    "res['u2']['i2'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('u1' in res, 'a' in res)\n",
    "print('u1' in res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['head1', 'i1', 'i2']\n"
     ]
    }
   ],
   "source": [
    "l1 = ['head1']\n",
    "items = ['i1', 'i2']\n",
    "print(l1 + items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xavier Uniform Initialized Weights:\n",
      "tensor([[-0.5021, -0.5029, -0.2428, -0.0213],\n",
      "        [ 0.1326,  0.8364,  0.6794, -0.4628],\n",
      "        [-0.7714,  0.1131, -0.6915, -0.2788]])\n",
      "\n",
      "Xavier Normal Initialized Weights:\n",
      "tensor([[ 0.7360,  0.1673, -0.1899,  0.2551],\n",
      "        [ 0.0159, -0.4252, -0.0738, -0.3779],\n",
      "        [ 1.3428,  0.0142,  0.0664, -0.6059]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设我们有 4 个输入节点，3 个输出节点\n",
    "n_in, n_out = 4, 3\n",
    "\n",
    "# 创建一个权重张量，大小为 (n_out, n_in)\n",
    "weight = torch.empty(n_out, n_in)\n",
    "\n",
    "# 使用 Xavier 均匀分布初始化\n",
    "nn.init.xavier_uniform_(weight)\n",
    "print(\"Xavier Uniform Initialized Weights:\")\n",
    "print(weight)\n",
    "\n",
    "# 再次创建一个权重张量\n",
    "weight = torch.empty(n_out, n_in)\n",
    "\n",
    "# 使用 Xavier 正态分布初始化\n",
    "nn.init.xavier_normal_(weight)\n",
    "print(\"\\nXavier Normal Initialized Weights:\")\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3903, 0.7587, 0.7791],\n",
      "        [0.7873, 0.4488, 0.4789]])\n",
      "tensor([[0.8189, 0.5877, 0.4617],\n",
      "        [0.2679, 0.7100, 0.6516]])\n",
      "tensor([[0.3903, 0.7587, 0.7791],\n",
      "        [0.7873, 0.4488, 0.4789],\n",
      "        [0.8189, 0.5877, 0.4617],\n",
      "        [0.2679, 0.7100, 0.6516]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.rand((2,3))\n",
    "print(t1)\n",
    "t2 = torch.rand((2,3))\n",
    "print(t2)\n",
    "t3 = torch.cat([t1, t2], dim=0)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Matrix:\n",
      " tensor([[1, 0, 0],\n",
      "        [0, 0, 3],\n",
      "        [4, 0, 0]])\n",
      "Sparse Matrix:\n",
      " tensor(indices=tensor([[0, 1, 2],\n",
      "                       [0, 2, 0]]),\n",
      "       values=tensor([1, 3, 4]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建普通矩阵\n",
    "dense_matrix = torch.tensor([[1, 0, 0], [0, 0, 3], [4, 0, 0]])\n",
    "\n",
    "# 创建稀疏矩阵\n",
    "indices = torch.tensor([[0, 1, 2], [0, 2, 0]])  # 非零元素的行和列索引\n",
    "values = torch.tensor([1, 3, 4])  # 非零元素的值\n",
    "sparse_matrix = torch.sparse_coo_tensor(indices, values, (3, 3))\n",
    "\n",
    "print(\"Dense Matrix:\\n\", dense_matrix)\n",
    "print(\"Sparse Matrix:\\n\", sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix:\n",
      "  (0, 0)\t1\n",
      "  (1, 2)\t3\n",
      "  (2, 0)\t4\n",
      "<class 'torch.Tensor'>\n",
      "tensor(indices=tensor([[0, 1, 2],\n",
      "                       [0, 2, 0]]),\n",
      "       values=tensor([1., 3., 4.]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[0, 1, 2],\n",
      "                       [0, 2, 0]]),\n",
      "       values=tensor([1., 3., 4.]),\n",
      "       size=(3, 3), nnz=3, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "def convert_sparse_mat_to_tensor(X):\n",
    "    coo = X.tocoo()  # 转换为 COO 格式\n",
    "    indices = torch.LongTensor([coo.row, coo.col])\n",
    "    values = torch.from_numpy(coo.data).float()\n",
    "    return torch.sparse_coo_tensor(indices, values, coo.shape)\n",
    "\n",
    "\n",
    "def above(X):\n",
    "    coo = X.tocoo()  # 转换为 COO 格式\n",
    "    indices = torch.LongTensor(np.vstack([coo.row, coo.col]))\n",
    "    print(type(indices))\n",
    "    values = torch.from_numpy(coo.data).float()\n",
    "    return torch.sparse_coo_tensor(indices, values, coo.shape)\n",
    "\n",
    "# 创建一个 SciPy COO 稀疏矩阵\n",
    "data = np.array([1, 3, 4])\n",
    "row_indices = np.array([0, 1, 2])\n",
    "col_indices = np.array([0, 2, 0])\n",
    "sparse_matrix = sp.coo_matrix((data, (row_indices, col_indices)), shape=(3, 3))\n",
    "print(f'sparse matrix:\\n{sparse_matrix}')\n",
    "\n",
    "# 转换为 PyTorch 稀疏张量\n",
    "torch_sparse_tensor = convert_sparse_mat_to_tensor(sparse_matrix)\n",
    "result = above(sparse_matrix)\n",
    "\n",
    "print(torch_sparse_tensor)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "原始张量:\n",
      " tensor([[[3., 4.],\n",
      "         [1., 2.]],\n",
      "\n",
      "        [[2., 1.],\n",
      "         [4., 3.]]])\n",
      "沿着最后一个维度归一化后的张量:\n",
      " tensor([[[0.6000, 0.8000],\n",
      "         [0.4472, 0.8944]],\n",
      "\n",
      "        [[0.8944, 0.4472],\n",
      "         [0.8000, 0.6000]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 创建一个示例三维张量\n",
    "x = torch.tensor([[[3.0, 4.0], \n",
    "                    [1.0, 2.0]],\n",
    "\n",
    "                   [[2.0, 1.0], \n",
    "                    [4.0, 3.0]]])\n",
    "print(x.shape)\n",
    "# 沿着最后一个维度归一化\n",
    "normalized_dim_neg1 = F.normalize(x, p=2, dim=-1)\n",
    "\n",
    "print(\"原始张量:\\n\", x)\n",
    "print(\"沿着最后一个维度归一化后的张量:\\n\", normalized_dim_neg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9729,  1.5272,  0.4359],\n",
       "        [-0.1330, -0.5348,  0.4167]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0.9729,  1.5272,  0.4359],\n",
      "         [-0.1330, -0.5348,  0.4167]],\n",
      "\n",
      "        [[ 0.9729,  1.5272,  0.4359],\n",
      "         [-0.1330, -0.5348,  0.4167]]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.stack((x, x), dim=0)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9729,  1.5272,  0.4359],\n",
       "         [ 0.9729,  1.5272,  0.4359]],\n",
       "\n",
       "        [[-0.1330, -0.5348,  0.4167],\n",
       "         [-0.1330, -0.5348,  0.4167]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = torch.stack((x, x), dim=1)\n",
    "y1.shape\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9729,  0.9729],\n",
       "         [ 1.5272,  1.5272],\n",
       "         [ 0.4359,  0.4359]],\n",
       "\n",
       "        [[-0.1330, -0.1330],\n",
       "         [-0.5348, -0.5348],\n",
       "         [ 0.4167,  0.4167]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = torch.stack((x, x), dim=2)\n",
    "y2.shape\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0099,  2.3835],\n",
      "        [-0.8588, -0.6546],\n",
      "        [-1.1814, -0.4834]]) torch.Size([3, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(c, c\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(3,2)\n",
    "b = torch.randn(3,2)\n",
    "c = torch.mul(a,b)\n",
    "print(c, c.shape)\n",
    "d = torch.randn(2,3)\n",
    "print(torch.mul(a,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
