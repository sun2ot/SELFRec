{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama\n",
    "\n",
    "拟借助 Ollama 搭建本地大模型，使用 open-webui 进行 RAG 操作。\n",
    "\n",
    "阅读 ollama 文档，预计可使用以下功能：\n",
    "- Generate a completion\n",
    "- Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于 Ollama 的使用，这里纠正一个误区。`ollama run model` 命令会进入 CLI 交互模式，此时可以与大模型进行对话。\n",
    "\n",
    "但如果只是需要调用模型 API，执行 `ollama serve` 即可。此时 ollama 会监听本地的 11434 端口，并提供 RESTful API。直接按照[API 文档](https://github.com/ollama/ollama/blob/main/docs/api.md)发起请求，ollama 会加载模型到 GPU 进行计算。\n",
    "\n",
    "此外，如果一段时间内没有请求，**模型会自动卸载**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "[ollama 局域网访问配置](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北京\n"
     ]
    }
   ],
   "source": [
    "url_generate = \"http://172.16.33.242:11434/api/generate\"\n",
    "def get_response(url, data):\n",
    "    response = requests.post(url, json=data)\n",
    "    response_dict = json.loads(response.text)\n",
    "    response_content = response_dict[\"response\"]\n",
    "    return response_content\n",
    "\n",
    "data = {\n",
    "    \"model\": \"llama3.1\",\n",
    "    \"prompt\": \"中国的首都是哪？\",\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "\n",
    "res = get_response(url_generate,data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain 是一个用于开发由大型语言模型(LLMs)支持的应用程序的框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# 指定《奥德赛》在Project Gutenberg上的URL\n",
    "odyssey_url = \"http://whr.085404.xyz/基础指南/Linux docs for the newers.html\"\n",
    "\n",
    "# 实例化WebBaseLoader并加载文档\n",
    "#loader = WebBaseLoader(odyssey_url)\n",
    "loader = UnstructuredMarkdownLoader(\n",
    "    file_path='mk_dataset/RAG/漆黑的魅影攻略.md',\n",
    "    mode='single'\n",
    ")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/home/yzh/code/SELFRec/dataset/RAG/漆黑的魅影攻略.md'}, page_content='title: 漆黑的魅影攻略 date: 2023-08-31 19:16:00 updated: 2023-09-03 10:06:12 categories: - 教程 - 游戏 tags: - game url: /method/pokemon-dark-phantom katex: \"false\"\\n\\n神兽\\n\\n水君\\n\\n冥想+冲浪+冷冻光线+空气切割\\n\\n性格：大胆/保守 特性：贮水\\n\\n努力HP物防，可以考虑分点给特攻。通关比较推荐的类型，冥想三攻，水冰飞的盲点本作就电灯鱼和钢企鹅，打击面很不错，想节约点药钱的可以把一攻换成睡觉。\\n\\n雷公\\n\\n紫瑾市精灵中心门口的老头，接任务，拿到地道钥匙 从精灵中心往左下走，到钓鱼老哥那，下水，然后往右到洞口小岛\\n\\n性格推荐：保守 技能：伏特替换、反射壁、十万伏特和神通力\\n\\n闪电鸟\\n\\n地点：卡那兹市上方，流星瀑布最里面\\n\\n快龙：龙舞+龙之爪/逆鳞+火焰拳+地震， 性格：固执 特性：精神力 努力：物攻速度\\n\\n技能\\n\\n学习技能： - 冬雪市，精灵中心往左第二间屋子，技能指导员 - 每次学习需要一个心之鳞片\\n\\n遗忘技能： - 水静市，超级市场右边的遗忘老人 - 冲浪术必须在背包里另一个精灵也学了的情况下，才能遗忘\\n\\n金手指\\n\\ncb： code breaker ，也被称为代码断路器、CB码。格式为：8位十六进制数 4位十六进制数。具体来说，CB码的一行是由单个空格分隔的一个8位十六进制数和一个4位十六进制数，这一行除了两个数字、单个空格和结尾那个看不见的回车符，没有任何其他符号。\\n\\ngs： gameshark\\n\\n类型 作用 代码 备注 cb 商店购买物品时，替换为制定物品 83005E12 xxxx xxxx 为物品代码，似乎仅在古辰镇生效 cb 不会遇到野生精灵 820375D4 0000 等价于喷雾 gs 快速升级 020241F0:2710 对战前开启，升到需要等级后即可关闭 gs 开启遇宠（将随机碰到的野生宠物固定为某一个） 0146DCEA 3E32A31D cb 指定遇到的宠物 83007E28 xxxx xxxx 为宠物代码，该指令在 开启遇宠 打开后方可生效\\n\\n[!warning] 在 PC 端的 visualboyadvance 模拟器中，本人使用的 visualboyadvance-m v2.1.5 在输入 gameshark 码时，会自动去除中间的空格，且这样的 gs 码无法正常生效。因此输入时，视情况先手动去除中间空格再输入金手指\\n\\n物品代码&宠物代码\\n\\nhttps://gist.github.com/sun2ot/468c138c206e770bd8ecd81a83e1b658\\n\\n努力值\\n\\n凯那市买药，9800/瓶，一瓶加 10 点努力值 努力值总上限 510 点，单项上限 255，吃药只能加到 100\\n\\n水静市超级市场，可以买编号 21-26 号树果，吃了会下降 10 点相应的努力值，刷错努力值的时候可以拿这个来清空。\\n\\n紫堇市（电系道馆）的精灵中心门口正下方的男的可以看队首精灵的个体值，左边旁边电玩城旁边的戴眼镜的男的可以看队首精灵的努力值。\\n\\n打什么精灵加什么努力的话，最简单的就是“反转世界”轮回镇那里，其他的一周目的精灵的对应努力值。不过建议前期不要在乎这个，等进轮回镇了再刷努力也来得及。')]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 实例化文本分割器，设置每块的字符数\n",
    "# chunk_overlap参数设置为0意味着文本块之间没有重叠\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "\n",
    "# 分割文档\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 实例化嵌入模型\n",
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")\n",
    "\n",
    "# 使用文档块创建向量数据库\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=oembed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据提供的上下文，“遗忘老人”位于水静市的一个超级市场的右侧。'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import  StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = Ollama(base_url=\"http://localhost:11434\", model=\"qwen2\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke(\"遗忘老人在哪？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
