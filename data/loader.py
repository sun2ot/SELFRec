import os.path
from os import remove
from re import split
from typing import Literal
import torch
import torch.nn as nn
from safetensors import safe_open
from util.logger import Log
import tqdm
import json

class FileIO(object):
    def __init__(self):
        pass

    @staticmethod
    def write_file(dir: str, file: str, content, op='w'):
        """
        å°†å†…å®¹å†™å…¥æŒ‡å®šè·¯å¾„å’Œæ–‡ä»¶åçš„æ–‡ä»¶ä¸­

        Args:
            dir: æ–‡ä»¶è·¯å¾„
            file: æ–‡ä»¶å
            content: å†™å…¥çš„å†…å®¹
            op: å†™å…¥æ–¹å¼ï¼Œé»˜è®¤ä¸º`w`ï¼Œå³è¦†ç›–
        """
        if not os.path.exists(dir):
            os.makedirs(dir)
        with open(dir + file, op) as f:
            f.writelines(content)

    @staticmethod
    def delete_file(file_path):
        if os.path.exists(file_path):
            remove(file_path)

    @staticmethod
    def load_data_set(file: str, rec_type: Literal['graph', 'sequential']):
        """
        æ ¹æ®æ¨¡å‹ç±»å‹åŠ è½½æ•°æ®é›†

        Args:
            file: æ•°æ®é›†è·¯å¾„
            rec_type: `graph` or `sequential`
        
        Returns:
            data (graph): List[[user, item, float(weight)], [...]]
        """
        if rec_type == 'graph':
            data = []
            with open(file) as f:
                for line in f:
                    # user_id, item_id, weight
                    items = line.strip().split(' ')
                    user_id = items[0]
                    item_id = items[1]
                    weight = items[2]
                    #? ä¸ºå•¥è¦è½¬float???
                    # data.append([user_id, item_id, float(weight)])
                    data.append([user_id, item_id, weight])

        elif rec_type == 'sequential':
            data = {}
            with open(file) as f:
                for line in f:
                    items = split(':', line.strip())
                    seq_id = items[0]
                    data[seq_id]=items[1].split()
        return data

    @staticmethod
    def load_user_list(file):
        user_list = []
        print('loading user List...')
        with open(file) as f:
            for line in f:
                user_list.append(line.strip().split()[0])
        return user_list

    @staticmethod
    def load_social_data(file):
        social_data = []
        print('loading social data...')
        with open(file) as f:
            for line in f:
                items = split(' ', line.strip())
                user1 = items[0]
                user2 = items[1]
                if len(items) < 3:
                    weight = 1
                else:
                    weight = float(items[2])
                social_data.append([user1, user2, weight])
        return social_data
    

    @staticmethod
    def load_image_data(image_set: str, 
                        item2image: str, 
                        emb_size: int, 
                        device_id: int) -> dict[str, torch.Tensor]:
        """
        åŠ è½½å›¾ç‰‡æ•°æ®é›†ï¼š
        è¯»å–å›¾åƒé¢„å¤„ç†æ•°æ®å¹¶ä»CLIPæ¨¡å‹è¾“å‡ºçš„512ç»´æŠ•å½±åˆ°embedding_size

        Args:
            image_set (str): safetensors æ–‡ä»¶è·¯å¾„
            item2image (str): item -> å›¾ç‰‡æ˜ å°„æ–‡ä»¶
            emb_size (int): æŠ•å½±ç»´åº¦
        
        Returns:
            image_embs (dict): item (str) -> mean image embedding (pytorch tensor)
        """
        image_embs: dict[str, torch.Tensor] = {}  # item -> mean image embedding
        device = torch.device(f"cuda:{device_id}" if torch.cuda.is_available() else "cpu")
        # å®šä¹‰ä¸€ä¸ªçº¿æ€§å±‚å°†512ç»´å›¾åƒç‰¹å¾æ˜ å°„åˆ°emb_size
        linear_projection = nn.Linear(512, emb_size, device=device)

        with safe_open(image_set, 'pt', device=f"cuda:{device_id}") as image_safetensors: # type: ignore
            with open(item2image, 'r') as map_file:
                Log.cli('Loader', f'ğŸ“· Loading image safetensors to cuda:{device_id} and project to {emb_size} dimensions')
                for line in tqdm.tqdm(map_file, desc='items'):
                    item = line.strip().split(' ')[0]
                    images = line.strip().split(' ')[1:]
                    try:
                        image_embs[item] = linear_projection(
                            torch.mean(
                            torch.stack([image_safetensors.get_tensor(image) for image in images]), dim=0)
                            )
                    except Exception as e:
                        Log.catch(e, item, 'item2photo emb project')
                        # print(f'\n{"-"*50}\n{item} error:\n{e}\n{"-"*50}')
                        exit(-1)
                        
        return image_embs


    @staticmethod
    def load_text_data(path: str, device_id: int) -> safe_open:
        """åŠ è½½æ–‡æœ¬æ¨¡æ€æ•°æ®: è¯»å–æ–‡æœ¬é¢„å¤„ç†æ•°æ®å¹¶ä»stellaæ¨¡å‹è¾“å‡ºçš„1024ç»´æŠ•å½±åˆ°embedding_size

        Args:
            path (str): safetensors æ–‡ä»¶è·¯å¾„

        Returns:
            text_embs (dict[str, torch.Tensor])
        """
        #! è¿™é‡Œè·Ÿå›¾åƒæ¨¡æ€åšä¸ªåŒºåˆ†å°è¯•, ç›´æ¥è¿”å›ä¸€ä¸ª safe_open class, å› ä¸ºè¿™ç©æ„æ˜¯ lazy load
        # æ­£å¥½ç»Ÿä¸€é€»è¾‘, æ•°æ®å¤„ç†åœ¨ Interaction é‡Œåš
        # æ‰€ä»¥æŸç§æ„ä¹‰ä¸Šè¯´, safetensors å®˜æ–¹çš„ docs æ˜¯é”™çš„... å› ä¸º safe_open æ²¡æœ‰å®ç° with ä¸Šä¸‹æ–‡åŠŸèƒ½
        text_safetensors =  safe_open(path, 'pt', device=f"cuda:{device_id}")
        Log.cli('Loader', f'ğŸ“’ Loading text safetensors to cuda:{device_id}')
        
        return text_safetensors