from base.recommender import Recommender
from data.ui_graph import Interaction
from util.algorithm import find_k_largest
from time import strftime, localtime, time
from data.loader import FileIO
import os
from os.path import abspath
from util.evaluation import ranking_evaluation
from dotenv import load_dotenv
from qywx_bot.bot import Bot

load_dotenv()
key = os.getenv('WEBHOOK_KEY')
if key is not None:
    bot: Bot = Bot(key)


class GraphRecommender(Recommender):
    def __init__(self, conf, training_set, test_set, **kwargs):
        super().__init__(conf, training_set, test_set, **kwargs)
        self.data = Interaction(conf, training_set, test_set, **kwargs)
        self.bestPerformance = []  # [epoch, performance{recall:0.0, precision:0.0, ...}]
        self.topN = [int(num) for num in self.ranking]  # 10, 20
        self.max_N = max(self.topN)

    def print_model_info(self):
        """é‡å†™çˆ¶ç±»æ–¹æ³•è¾“å‡ºæ¨¡å‹é…ç½®åŠæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        super().print_model_info()
        # print dataset statistics
        print(f'Training Set Size: (user number: {self.data.training_size()[0]}, '
              f'item number: {self.data.training_size()[1]}, '
              f'interaction number: {self.data.training_size()[2]})')
        print(f'Test Set Size: (user number: {self.data.test_size()[0]}, '
              f'item number: {self.data.test_size()[1]}, '
              f'interaction number: {self.data.test_size()[2]})')
        print('=' * 80)

    def build(self):
        pass

    def train(self):
        pass

    def predict(self, u):
        raise NotImplementedError

    def test(self):
        """
        æµ‹è¯•æ¨¡å‹

        Returns:
            rec_list (dict): æ¨èåˆ—è¡¨ `{user: [(item1, score1), (item2, score2), ...]}`
        """
        def process_bar(num, total):
            """
            ç»˜åˆ¶CLIè¿›åº¦æ¡

            Args:
                num (int): å½“å‰å®Œæˆçš„ä»»åŠ¡æ•°é‡
                total (int): ä»»åŠ¡çš„æ€»æ•°é‡
            """
            # è®¡ç®—ä»»åŠ¡å®Œæˆçš„æ¯”ç‡
            rate = float(num) / total
            # æ ¹æ®æ¯”ç‡è®¡ç®—éœ€è¦æ˜¾ç¤ºçš„è¿›åº¦æ¡é•¿åº¦(æœ€é•¿50ä¸ªå­—ç¬¦)
            ratenum = int(50 * rate)
            print(f'\rProgress: [{"+" * ratenum}{" " * (50 - ratenum)}]{ratenum * 2}%', end='', flush=True)

        rec_list = {}
        user_count = len(self.data.test_set)
        for i, user in enumerate(self.data.test_set):
            # ç”Ÿæˆç”¨æˆ·æ¨èå€™é€‰
            candidates = self.predict(user)  # (38048,)
            #? è¿™æ˜¯å¦æ„å‘³ç€è¯„åˆ†å…¶å®ä¸å½±å“é¢„æµ‹ç»“æœ
            #* ans: yesï¼Œå› ä¸ºå‹æ ¹æ²¡æœ‰ç”¨åˆ°ï¼Œæ²¡çœ‹åˆ°å˜é‡åéƒ½æ˜¯ _ å—ğŸ¤£
            rated_list, _ = self.data.user_rated(user)
            # æ ¹æ®ç”¨æˆ·å†å²è¯„åˆ†ï¼Œæ’é™¤å·²è¯„åˆ†é¡¹ç›®(èµ‹æå°å€¼)
            #? æ‰€ä»¥æµ‹è¯•é›†é‡Œä¸ºä»€ä¹ˆä¼šå­˜åœ¨å·²è¯„åˆ†é¡¹ç›®
            #* ans: ui_graph.__generate_set() ä¸­å·²è¿‡æ»¤
            for item in rated_list:
                #* ä»¥item_idä¸ºç´¢å¼•è·å–å¯¹åº”è¯„åˆ†å¹¶ä¿®æ”¹
                candidates[self.data.item[item]] = -10e8
            # æ‰¾åˆ°è¯„åˆ†æœ€é«˜çš„max_Nä¸ªç‰©å“
            ids, scores = find_k_largest(self.max_N, candidates)
            item_names = [self.data.id2item[iid] for iid in ids]
            # å­˜å‚¨æ¨èç»“æœ
            rec_list[user] = list(zip(item_names, scores))
            # æ¯å¤„ç†1000ä¸ªç”¨æˆ·ï¼Œæ›´æ–°è¿›åº¦æ¡
            if i % 1000 == 0:
                process_bar(i, user_count)
        # å®Œæˆæ‰€æœ‰ç”¨æˆ·æ¨èåï¼Œè¿›åº¦æ¡æ‹‰åˆ°100%(å› ä¸ºæ­£å¸¸éå†æ˜¯æ— æ³•æ˜¾ç¤ºå‡º100%çš„)
        process_bar(user_count, user_count)
        print('')
        return rec_list

    def evaluate(self, rec_list):
        #* ä»…åœ¨æ‰€æœ‰è®­ç»ƒepochç»“æŸåæ‰§è¡Œä¸€æ¬¡
        """
        è¾“å‡ºæ¨èæŒ‡æ ‡åŠç»“æœ

        Args:
            rec_list (dict): æ¨èåˆ—è¡¨ `{user: [(item1, score1), (item2, score2), ...]}`
        """
        self.recOutput.append('userId: recommendations in (itemId, ranking score) pairs, * means the item is hit.\n')
        # ç»“æœè¾“å‡ºæ ·ä¾‹
        # 0: (771,3.333857297897339) (649,3.1552059650421143) (...)
        for user in self.data.test_set:
            line = user + ':' + ''.join(
                f" ({item[0]},{item[1]}){'*' if item[0] in self.data.test_set[user] else ''}"
                for item in rec_list[user]
            )
            line += '\n'
            self.recOutput.append(line)
        current_time = strftime("%Y-%m-%d %H-%M-%S", localtime(time()))
        out_dir = self.output
        file_name = f"{self.config['model']['name']}@{current_time}-top-{self.max_N}items.txt"
        FileIO.write_file(out_dir, file_name, self.recOutput)
        print('The result has been output to ', abspath(out_dir), '.')
        # è¾“å‡ºè¯„ä¼°æŒ‡æ ‡åˆ°æ–‡ä»¶
        file_name = f"{self.config['model']['name']}@{current_time}-performance.txt"
        self.result = ranking_evaluation(self.data.test_set, rec_list, self.topN)
        # æ—¥å¿—è¾“å‡ºè¯„ä¼°æŒ‡æ ‡
        self.model_log.add('###Evaluation Results###')
        result_format_str = '\n'
        for r in self.result:
            result_format_str += r
        self.model_log.add(result_format_str)
        FileIO.write_file(out_dir, file_name, self.result)
        # CLI è¾“å‡ºè¯„ä¼°æŒ‡æ ‡
        print(f'The result of {self.model_name}:\n{"".join(self.result)}')
        bot.send_text(f'The result of {self.model_name}:\n{"".join(self.result)}')

    def fast_evaluation(self, epoch):
        """
        è¾“å‡ºå•è½®è¯„ä¼°æŒ‡æ ‡å¹¶è®°å½•æœ€ä½³æ€§èƒ½

        Returns:
            measure (list): é€å…ƒç´ å¯¹åº”é€è¡Œè¯„ä¼°æŒ‡æ ‡è¾“å‡º
        """
        print('Evaluating the model...')
        rec_list = self.test()
        measure = ranking_evaluation(self.data.test_set, rec_list, [self.max_N])

        performance = {k: float(v) for m in measure[1:] for k, v in [m.strip().split(':')]}

        if self.bestPerformance:
            count = sum(1 if self.bestPerformance[1][k] > performance[k] else -1 for k in performance)
        # å¦‚æœå­˜åœ¨ä¹‹å‰çš„æœ€ä½³æ€§èƒ½è®°å½•
        if len(self.bestPerformance) > 0:
            count = 0
            performance = {}
            # è§£æå½“å‰æ€§èƒ½æŒ‡æ ‡ï¼Œå­˜å‚¨åˆ°performanceå­—å…¸ä¸­
            #? measure[0]ä¸ºæ—¥å¿—ï¼Œä½†æ˜¯top-Nå€¼æœ‰ä¸¤ä¸ªï¼Œä¹Ÿå°±æ˜¯è¯´åé¢åº”è¯¥è¿˜æœ‰ä¸€ä¸ªæ—¥å¿—è®°å½•ï¼Œå¦‚ä½•å¤„ç†çš„
            for m in measure[1:]:
                k, v = m.strip().split(':')
                performance[k] = float(v)
            # æ¯”è¾ƒå½“å‰æ€§èƒ½å’Œæœ€ä½³æ€§èƒ½ï¼Œæ›´æ–°countå€¼
            for k in self.bestPerformance[1]:
                # å¦‚æœå½“å‰æ€§èƒ½æŒ‡æ ‡å°äºæœ€ä½³æ€§èƒ½æŒ‡æ ‡(æŸå¤±å‡½æ•°å€¼è¶Šå°è¶Šå¥½)ï¼Œåˆ™count-1
                if self.bestPerformance[1][k] > performance[k]:
                    count += 1
                else:
                    count -= 1
            # é€šè¿‡countå€¼ç²—ç•¥åˆ¤æ–­æ˜¯å¦æ•´ä½“æ›´ä¼˜(å³å¤šæ•°æŒ‡æ ‡æ›´ä¼˜)
            if count < 0:
                self.bestPerformance = [epoch + 1, performance]
                #? ç»§æ‰¿è‡ªçˆ¶ç±»çš„saveå‡½æ•°æ˜¯å¹²å˜›çš„
                self.save()
        else:
            self.bestPerformance = [epoch + 1, performance]
            # ä¸å­˜åœ¨å†å²æœ€ä½³æ€§èƒ½è®°å½•ï¼Œåˆ™ç›´æ¥ä¿å­˜
            self.bestPerformance.append(epoch + 1)
            performance = {}
            for m in measure[1:]:
                k, v = m.strip().split(':')
                performance[k] = float(v)
            self.bestPerformance.append(performance)
            self.save()

        print('-' * 80)
        print(f'Real-Time Ranking Performance (Top-{self.max_N} Item Recommendation)')
        measure_str = ', '.join([f'{k}: {v}' for k, v in performance.items()])
        print(f'*Current Performance*\nEpoch: {epoch + 1}, {measure_str}')
        bp = ', '.join([f'{k}: {v}' for k, v in self.bestPerformance[1].items()])
        print(f'*Best Performance*\nEpoch: {self.bestPerformance[0]}, {bp}')
        print('-' * 80)
        return measure
